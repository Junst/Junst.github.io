---
layout: single
title: Projects
permalink: /projects/
classes: wide
---

## AIBA — Attention-based Instrument Band Alignment
- **Conference**: NeurIPS 2025 Workshop (AI for Music)  
- **What it does**: Aligns attention maps from text-to-audio diffusion models with instrument frequency bands, enabling interpretable control.  
- **Links**: [Workshop](https://aiformusicworkshop.github.io/) · [arXiv](https://arxiv.org/abs/2509.20891) · [PDF](https://arxiv.org/pdf/2509.20891)

---

## Jamendo-QA — Large-Scale Music Question Answering Dataset
- **Conference**: Submitted to ICASSP 2026  
- **What it does**: Builds a large-scale QA dataset from Jamendo music tracks, combining captions, tags, and questions for training multimodal LLMs.  
- **Links**: [arXiv](https://arxiv.org/abs/2509.15662) · [PDF](https://arxiv.org/pdf/2509.15662) · [HuggingFace](https://huggingface.co/datasets/m-a-a-p/Jamendo-QA)

---

## MINO (Music-DINO)
- **Status**: Research in progress  
- **What it does**: Adapts DINO self-distillation to music by using CQT spectrograms, harmonic-aware positional encoding, and dual-axis attention to capture pitch, harmony, and tempo.  
- **Links**: (coming soon: code + paper)

---

## Let Triggers Control — Frequency-aware Dropout
- **Status**: Under Review  
- **What it does**: Introduces a frequency-aware dropout method for token control, enabling better handling of trigger tokens in generative models.  
- **Links**: (preprint link coming soon)

---

## Illustrious — Open Advanced Illustration Model
- **Status**: Technical Report (2024)  
- **What it does**: Large-scale illustration generation model with open release for research and creative use.  
- **Links**: [arXiv](https://arxiv.org/abs/2409.19946) · [PDF](https://arxiv.org/pdf/2409.19946) · [HuggingFace](https://huggingface.co/OnomaAIResearch/Illustrious-xl-early-release-v0) · [CivitAI](https://civitai.com/models/795765/illustrious-xl)

---

## Contrastive Adapter Training (CAT) — Personalized Image Generation
- **Conference**: CVPR 2024 Workshop (Generative Models for Computer Vision)  
- **What it does**: Proposes a contrastive adapter training strategy to personalize diffusion models.  
- **Links**: [Workshop](https://generative-vision.github.io/workshop-CVPR-24/) · [arXiv](https://arxiv.org/abs/2404.07554) · [PDF](https://arxiv.org/pdf/2404.07554.pdf)
